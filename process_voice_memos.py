#!/usr/bin/env python3
"""
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ–‡å­—èµ·ã“ã—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

00ãƒœã‚¤ã‚¹ãƒ¡ãƒ¢å†…ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«æ–‡å­—èµ·ã“ã—ã—ã€
AIåˆ†æã§æ§‹é€ åŒ–ãƒ»è¦ç´„ã—ã¦ã€Obsidianãƒãƒ¼ãƒˆã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
"""
import os
import sys
from pathlib import Path
from datetime import datetime
import shutil
import json

def load_env():
    """ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        from dotenv import load_dotenv
        env_path = Path(__file__).parent / '.env'
        load_dotenv(dotenv_path=env_path)
    except ImportError:
        print("è­¦å‘Š: python-dotenvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("pip install python-dotenv")

def get_openai_client():
    """OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    try:
        from openai import OpenAI
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key or api_key == "your-api-key-here":
            print("ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print(".envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return None
        return OpenAI(api_key=api_key)
    except ImportError:
        print("ã‚¨ãƒ©ãƒ¼: openaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("pip install openai")
        return None

def find_audio_files(voice_memo_dir):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º"""
    audio_extensions = ['.m4a', '.mp3', '.wav', '.mp4']
    audio_files = []
    
    for file in Path(voice_memo_dir).iterdir():
        if file.is_file() and file.suffix.lower() in audio_extensions:
            audio_files.append(file)
    
    return audio_files

def find_existing_transcript(audio_file, voice_memo_dir, processed_dir):
    """æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    base_name = audio_file.stem
    
    # 00ãƒœã‚¤ã‚¹ãƒ¡ãƒ¢å†…ã‚’æ¤œç´¢
    txt_path = Path(voice_memo_dir) / f"{base_name}.txt"
    if txt_path.exists():
        print(f"âœ“ æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹: {txt_path}")
        return txt_path
    
    # processedå†…ã‚’æ¤œç´¢
    txt_path_processed = Path(processed_dir) / f"{base_name}.txt"
    if txt_path_processed.exists():
        print(f"âœ“ æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ï¼ˆprocessedå†…ï¼‰: {txt_path_processed}")
        return txt_path_processed
    
    # _æ–‡å­—èµ·ã“ã—.txtå½¢å¼ã‚‚æ¤œç´¢
    txt_path_alt = Path(voice_memo_dir) / f"{base_name}_æ–‡å­—èµ·ã“ã—.txt"
    if txt_path_alt.exists():
        print(f"âœ“ æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹: {txt_path_alt}")
        return txt_path_alt
    
    return None

def transcribe_audio(audio_file, client):
    """OpenAI Whisper APIã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—"""
    print(f"ğŸ¤ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ä¸­: {audio_file.name}")
    print("   OpenAI Whisper APIã«é€ä¿¡ã—ã¦ã„ã¾ã™...")
    
    try:
        with open(audio_file, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                language="ja"
            )
        
        text = transcript.text
        print(f"âœ“ æ–‡å­—èµ·ã“ã—å®Œäº†ï¼ˆ{len(text)}æ–‡å­—ï¼‰")
        
        # .txtãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        txt_path = audio_file.parent / f"{audio_file.stem}.txt"
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(text)
        print(f"âœ“ æ–‡å­—èµ·ã“ã—ã‚’ä¿å­˜: {txt_path}")
        
        return text
    except Exception as e:
        print(f"âœ— æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def analyze_and_structure(transcript_text, client):
    """AIã§æ–‡å­—èµ·ã“ã—ã‚’åˆ†æãƒ»æ§‹é€ åŒ–"""
    print("ğŸ¤– AIã§åˆ†æãƒ»æ§‹é€ åŒ–ä¸­...")
    
    prompt = f"""ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å½¢å¼ã§JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š

{{
  "title": "å†…å®¹ã‚’è¡¨ã™ç°¡æ½”ãªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ20æ–‡å­—ä»¥å†…ï¼‰",
  "summary": "3-5è¡Œç¨‹åº¦ã®è¦ç´„",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3"],
  "sections": [
    {{"heading": "è¦‹å‡ºã—1", "content": "ã“ã®è¦‹å‡ºã—ã«é–¢é€£ã™ã‚‹å†…å®¹ã®è¦ç´„"}},
    {{"heading": "è¦‹å‡ºã—2", "content": "ã“ã®è¦‹å‡ºã—ã«é–¢é€£ã™ã‚‹å†…å®¹ã®è¦ç´„"}}
  ]
}}

æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ:
{transcript_text}
"""
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯éŸ³å£°ãƒ¡ãƒ¢ã‚’åˆ†æã—ã€æ§‹é€ åŒ–ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…ãšJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        print("âœ“ AIåˆ†æå®Œäº†")
        return result
    except Exception as e:
        print(f"âœ— AIåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªæ§‹é€ ã‚’è¿”ã™
        return {
            "title": "éŸ³å£°ãƒ¡ãƒ¢",
            "summary": transcript_text[:200] + "...",
            "tags": ["éŸ³å£°ãƒ¡ãƒ¢", "æ–‡å­—èµ·ã“ã—"],
            "sections": []
        }

def create_obsidian_note(audio_file, transcript_text, analysis, output_dir):
    """Obsidianãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    print("ğŸ“ Obsidianãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ—¥ä»˜_ã‚¿ã‚¤ãƒˆãƒ«å½¢å¼ï¼‰
    today = datetime.now().strftime("%Y-%m-%d")
    safe_title = analysis['title'].replace('/', '_').replace('\\', '_')
    output_filename = f"{today}_{safe_title}.md"
    output_path = Path(output_dir) / output_filename
    
    # YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼
    tags_yaml = "\n  - ".join(["æ–‡å­—èµ·ã“ã—", "éŸ³å£°"] + analysis.get('tags', []))
    frontmatter = f"""---
ã‚¿ã‚¤ãƒˆãƒ«: {analysis['title']}
ä½œæˆæ—¥: {today}
å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {audio_file.name}
ã‚¿ã‚°:
  - {tags_yaml}
ã‚«ãƒ†ã‚´ãƒª: éŸ³å£°ãƒ¡ãƒ¢
---

"""
    
    # éŸ³å£°åŸ‹ã‚è¾¼ã¿ãƒªãƒ³ã‚¯
    audio_embed = f"![[{audio_file.name}]]\n\n"
    
    # è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    summary_section = f"""## ğŸ“ è¦ç´„

{analysis['summary']}

"""
    
    # æ§‹é€ åŒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    structured_section = ""
    if analysis.get('sections'):
        structured_section = "## ğŸ—‚ï¸ å†…å®¹\n\n"
        for section in analysis['sections']:
            structured_section += f"### {section['heading']}\n\n{section['content']}\n\n"
    
    # å…¨æ–‡æ–‡å­—èµ·ã“ã—
    transcript_section = f"""## ğŸ“„ å…¨æ–‡æ–‡å­—èµ·ã“ã—

{transcript_text}

---

*æ–‡å­—èµ·ã“ã—æ—¥æ™‚: {today}*  
*ä½¿ç”¨ãƒ„ãƒ¼ãƒ«: OpenAI Whisper API*
"""
    
    # çµåˆ
    content = frontmatter + audio_embed + summary_section + structured_section + transcript_section
    
    # ä¿å­˜
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(content)
    
    print(f"âœ“ Obsidianãƒãƒ¼ãƒˆã‚’ä¿å­˜: {output_path}")
    return output_path

def move_to_processed(audio_file, processed_dir):
    """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
    print(f"ğŸ“¦ å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•ä¸­...")
    
    processed_path = Path(processed_dir)
    processed_path.mkdir(parents=True, exist_ok=True)
    
    destination = processed_path / audio_file.name
    
    # åŒåãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ã‘ã‚‹
    if destination.exists():
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        destination = processed_path / f"{audio_file.stem}_{timestamp}{audio_file.suffix}"
    
    shutil.move(str(audio_file), str(destination))
    print(f"âœ“ ç§»å‹•å®Œäº†: {destination}")

def process_single_file(audio_file, voice_memo_dir, processed_dir, output_dir, client):
    """1ã¤ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
    print(f"\n{'='*60}")
    print(f"å‡¦ç†é–‹å§‹: {audio_file.name}")
    print(f"{'='*60}")
    
    # 1. æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ã‚’æ¤œç´¢
    existing_txt = find_existing_transcript(audio_file, voice_memo_dir, processed_dir)
    
    if existing_txt:
        # æ—¢å­˜ã®.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        with open(existing_txt, "r", encoding="utf-8") as f:
            transcript_text = f.read()
        print(f"âœ“ æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ã‚’ä½¿ç”¨ï¼ˆ{len(transcript_text)}æ–‡å­—ï¼‰")
    else:
        # æ–°è¦æ–‡å­—èµ·ã“ã—
        transcript_text = transcribe_audio(audio_file, client)
        if not transcript_text:
            print("âœ— æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return False
    
    # 2. AIåˆ†æ
    analysis = analyze_and_structure(transcript_text, client)
    
    # 3. Obsidianãƒãƒ¼ãƒˆç”Ÿæˆ
    note_path = create_obsidian_note(audio_file, transcript_text, analysis, output_dir)
    
    # 4. å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
    move_to_processed(audio_file, processed_dir)
    
    print(f"âœ“ å‡¦ç†å®Œäº†: {audio_file.name}")
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ–‡å­—èµ·ã“ã—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")
    print("="*60)
    
    # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
    load_env()
    
    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
    client = get_openai_client()
    if not client:
        sys.exit(1)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    base_dir = Path(__file__).parent
    voice_memo_dir = base_dir / "00ãƒœã‚¤ã‚¹ãƒ¡ãƒ¢"
    output_dir = base_dir / "01æ–‡å­—èµ·ã“ã—"
    processed_dir = voice_memo_dir / "processed"
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
    if not voice_memo_dir.exists():
        print(f"ã‚¨ãƒ©ãƒ¼: {voice_memo_dir} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        sys.exit(1)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir.mkdir(exist_ok=True)
    processed_dir.mkdir(exist_ok=True)
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
    audio_files = find_audio_files(voice_memo_dir)
    
    if not audio_files:
        print(f"\néŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {voice_memo_dir}")
        print("å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return
    
    print(f"\næ¤œå‡ºã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {len(audio_files)}ä»¶")
    for f in audio_files:
        print(f"  - {f.name}")
    
    # ãƒãƒƒãƒå‡¦ç†
    success_count = 0
    fail_count = 0
    
    for audio_file in audio_files:
        try:
            if process_single_file(audio_file, voice_memo_dir, processed_dir, output_dir, client):
                success_count += 1
            else:
                fail_count += 1
        except Exception as e:
            print(f"âœ— ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            fail_count += 1
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print("å‡¦ç†å®Œäº†")
    print(f"{'='*60}")
    print(f"æˆåŠŸ: {success_count}ä»¶")
    print(f"å¤±æ•—: {fail_count}ä»¶")
    print(f"å‡ºåŠ›å…ˆ: {output_dir}")

if __name__ == "__main__":
    main()
